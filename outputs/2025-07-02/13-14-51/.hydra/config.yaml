datamodule:
  _target_: datamodule.goose_dataset.GooseDataModule
  root: /home/autokarthik/autoware.off-road/goose-dataset
  batch_size: 4
  num_workers: 8
  num_classes: 12
  img_size:
  - 512
  - 512
  scale_base:
  - 2048
  - 512
  ratio_range:
  - 0.5
  - 2.0
  mean:
  - 123.675
  - 116.28
  - 103.53
  std:
  - 58.395
  - 57.12
  - 57.375
model:
  _target_: models.segformer.segformer.LitSegFormer
  _recursive_: false
  variant: B2
  num_classes: ${datamodule.num_classes}
  optim_config: ${optim.optimizer}
  lr_scheduler_config: ${optim.scheduler}
optim:
  optimizer:
    _target_: torch.optim.AdamW
    lr: 6.0e-05
    weight_decay: 0.01
  scheduler:
    _target_: torch.optim.lr_scheduler.PolynomialLR
    _partial_: true
    total_iters: 160000
    power: 1.0
trainer:
  _target_: lightning.pytorch.Trainer
  max_epochs: 80
  accelerator: auto
  devices: auto
  precision: bf16-mixed
  strategy:
    _target_: ray.train.lightning.RayDDPStrategy
  plugins:
  - _target_: ray.train.lightning.RayLightningEnvironment
logger:
  _target_: lightning.pytorch.loggers.MLFlowLogger
  experiment_name: SegFormer
  tracking_uri: file:${hydra:runtime.output_dir}/mlruns
  log_model: true
ray:
  _target_: ray.train.ScalingConfig
  num_workers: 1
  use_gpu: true
  resources_per_worker:
    CPU: 1
    GPU: 1
callbacks:
  early_stop:
    _target_: lightning.pytorch.callbacks.EarlyStopping
    monitor: val_miou
    mode: max
    patience: 10
  ckpt:
    _target_: lightning.pytorch.callbacks.ModelCheckpoint
    monitor: val_miou
    mode: max
    save_top_k: 5
    save_last: true
    filename: segformer-{epoch:02d}-{val_miou:.4f}
  lr_monitor:
    _target_: lightning.pytorch.callbacks.LearningRateMonitor
    logging_interval: step
  ray_report:
    _target_: ray.train.lightning.RayTrainReportCallback
seed: 42
